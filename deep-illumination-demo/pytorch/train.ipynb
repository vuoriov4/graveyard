{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from model import NeRF\n",
    "from datasets import StanfordDragonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 593924\n",
      "Total images: 400\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dataset & model \n",
    "cuda = False\n",
    "dataset = StanfordDragonDataset(\"./datasets/dragon\")\n",
    "device = torch.device(\"cuda\") if (cuda) else torch.device(\"cpu\")\n",
    "min_bounds = torch.Tensor([-10,-10,-10]).to(device)\n",
    "max_bounds = torch.Tensor([10, 10, 10]).to(device)\n",
    "model = NeRF(device, min_bounds, max_bounds)\n",
    "if (cuda): model.cuda()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total model parameters: %d\" % total_params)\n",
    "print(\"Total images: %d\" % len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training variables\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "iterations = 1\n",
    "rays_per_batch = 2**11\n",
    "num_samples = 256\n",
    "all_positions = []\n",
    "all_directions = []\n",
    "all_gt_colors = []\n",
    "\n",
    "# Gather all rays\n",
    "for i in range(len(dataset)):\n",
    "    image, pose, focal = dataset[i]\n",
    "    positions, directions, gt_colors = model.get_rays(image, pose, focal)\n",
    "    all_positions.append(positions)\n",
    "    all_directions.append(directions)\n",
    "    all_gt_colors.append(gt_colors)\n",
    "\n",
    "# Concatenate all rays\n",
    "all_positions = torch.cat(all_positions, dim=0)\n",
    "all_directions = torch.cat(all_directions, dim=0)\n",
    "all_gt_colors = torch.cat(all_gt_colors, dim=0)\n",
    "\n",
    "# Shuffle rays\n",
    "shuffle = torch.randperm(all_positions.shape[0])\n",
    "all_positions = all_positions[shuffle]\n",
    "all_directions = all_directions[shuffle]\n",
    "all_gt_colors = all_gt_colors[shuffle]\n",
    "\n",
    "rays_per_iteration = all_positions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for i in range(iterations):\n",
    "    current_idx = 0\n",
    "    losses = []\n",
    "    while(current_idx < rays_per_iteration):\n",
    "        optimizer.zero_grad()\n",
    "        indices = torch.arange(current_idx, min(all_positions.shape[0], current_idx + rays_per_batch))\n",
    "        positions = all_positions[indices].to(device)\n",
    "        directions = all_directions[indices].to(device)\n",
    "        colors, depths, weights = model.render_rays(positions, directions, num_samples)\n",
    "        gt = all_gt_colors[indices].to(device)\n",
    "        loss = torch.mean(torch.square(colors - gt))\n",
    "        loss.backward()\n",
    "        current_idx += rays_per_batch\n",
    "        optimizer.step()\n",
    "        print('iteration: %d, loss: %.4f, ray count: %.2f%%' % (i, loss.item(), 100 * current_idx / rays_per_iteration))\n",
    "    torch.save(model.state_dict(), \"model-%d.pth\" % i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render testing data\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\") if (cuda) else torch.device(\"cpu\")\n",
    "min_bounds = torch.Tensor([-10,-10,-10]).to(device)\n",
    "max_bounds = torch.Tensor([10, 10, 10]).to(device)\n",
    "pth_model = NeRF(device, min_bounds, max_bounds)\n",
    "pth_model.load_state_dict(torch.load(\"model-0.pth\"))\n",
    "if (cuda): pth_model.cuda()\n",
    "pth_model.eval()\n",
    "testing_poses = torch.from_numpy(np.load(\"./testing_poses.npy\"))\n",
    "dummy_image, dummy_pose, focal = dataset[0]\n",
    "\n",
    "def render_image(idx):\n",
    "    with torch.no_grad():\n",
    "        pose = testing_poses[idx]\n",
    "        positions, directions, gt_colors = pth_model.get_rays(dummy_image, pose, focal)\n",
    "        current_idx = 0\n",
    "        color = torch.zeros(dummy_image.shape).reshape((-1, 3))\n",
    "        depth = torch.zeros(dummy_image.shape).reshape((-1, 3))\n",
    "        while(current_idx < positions.shape[0]):\n",
    "            indices = torch.arange(current_idx, min(positions.shape[0], current_idx + rays_per_batch))\n",
    "            pos = positions[indices].to(device)\n",
    "            dirs = directions[indices].to(device)\n",
    "            gt = gt_colors[indices].to(device)\n",
    "            colors, depths, _ = pth_model.render_rays(pos, dirs, num_samples)\n",
    "            color[indices] = colors.float().cpu()\n",
    "            depth[indices] = depths[..., None].float().cpu()\n",
    "            current_idx += rays_per_batch\n",
    "        color = color.reshape(dummy_image.shape) * 255\n",
    "        depth = depth.reshape(dummy_image.shape) * 255\n",
    "        pil_color = Image.fromarray(color.numpy().astype(np.uint8))\n",
    "        pil_color.save(\"test-color-%d.jpeg\" % idx)\n",
    "        pil_depth = Image.fromarray(depth.numpy().astype(np.uint8))\n",
    "        pil_depth.save(\"test-depth-%d.jpeg\" % idx)\n",
    "        \n",
    "for i in range(testing_poses.shape[0]): render_image(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
